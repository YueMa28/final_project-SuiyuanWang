---
title: "Mapping fine-scale population using dasymetric method"
author: Suiyuan Wang
subtitle: A case study in Buffalo city, NY
---

# Introduction

Knowledge of the fine-level population distribution is vital for measuring the impacts of socio-economic justice, optimizing resource allocation, and assessing the risks of environmental exposures. The traditional way to get population data is from the census bureau. However, population data released by the census bureau are too coarse and irregular to satisfy the requirements of accurate analysis. To solve the irregular shape and too coarse level problem of census data, we would downscale the census block group level data to census block. As for the method, the dasymetric method would be applied.  The dasymetric method uses locality knowledge to depict the uneven population distribution within zones without assuming even distributions. This volume preserve method disaggregates the population within the source zone to the target zones according to the weighted layer generated by population-related ancillary information to preserve the total population count. The dasymetric method has been evaluated as an effective and feasible way for population disaggregation. Finally, the result will be evaluated comparing with census block data. Overall, this project aims to apply the dasymetric method to disaggregate census data to get fine-level population data using open-source data.

# Materials and methods

## Load request packages for this project.
```{r, message=F, warning=F}
library(sf)
# install.packages("devtools")
# devtools::install_github("JaFro96/dasymetric")
#library(dasymetric)
library(leaflet)
library(piggyback)
library(tmap) 
library(lwgeom)
#install.packages("remotes")
#remotes::install_github("JaFro96/dasymetric")
#library(remotes)
#install_github("JaFro96/dasymetric")
# auth_token = Sys.getenv('GH_PAT')
knitr::opts_chunk$set(cache=TRUE)  # cache the results for quick compiling
```

## Data preprocessing
### Download data 

```{r}
dataurl = "https://github.com/geo511-2022/final_project-SuiyuanWang/releases/download/v1.0.2/Data_GEO511_project.zip"

#tdir=tempdir()
#download.file(dataurl,destfile=file.path(tdir,"temp.zip"))
#unzip(file.path(tdir,"temp.zip"),exdir = tdir) #unzip the compressed folder

download.file(dataurl,"temp.zip")
unzip("temp.zip") #unzip the compressed folder
```
```{r, echo=FALSE}

dasymetric_map <- function(target, source, ancillary_data, tid = NULL, extensive = NULL) {

  # Add IDs
  if(missing(tid)){
    target[['AW_tid']] <- 1:nrow(target)
    tid <- 'AW_tid'
  }
  source[['AW_sid']] <- 1:nrow(source)

  # Intersect Source to Intermediate
  first_int <- sf::st_intersection(source, ancillary_data)

  # Generate ID for Intersection
  first_int['AW_fid'] <- 1:nrow(first_int)

  # Compute Area for First Interpolation
  first_int['AW_area'] <- sf::st_area(first_int)

  # Calculate Area as a Proportion of Source Area
  cov_area <- first_int |>
    sf::st_drop_geometry() |>
    dplyr::group_by(.data$AW_sid) |>
    dplyr::summarise(AW_cov_area = sum(.data$AW_area))

  first_int <- dplyr::left_join(first_int, cov_area, by = 'AW_sid')
  first_int['AW_area_prp'] <- as.numeric(first_int$AW_area / first_int$AW_cov_area)

  # Multiply Extensive Variables by this Proportion
  for(i in extensive){
    first_int[[i]] <- first_int[[i]] * first_int[['AW_area_prp']]
  }

  # Intersect Again, Intermediate to Target
  target_int <- sf::st_intersection(first_int, target)

  # Calculate New Area (And Ratio)
  target_int['AW_t_area'] <- sf::st_area(target_int)
  target_int['AW_t_prp'] <- as.numeric(target_int[['AW_t_area']] / target_int[['AW_area']])

  # Multiply Extensive Again
  for(i in extensive){
    target_int[[i]] <- target_int[[i]] * target_int[['AW_t_prp']]
  }

  # Group And Summarise Extensive
  summary <- target_int |>
    sf::st_drop_geometry() |>
    dplyr::group_by(!!dplyr::sym(tid)) |>
    dplyr::summarise_at(extensive, sum)

  # Join To Target
  target <- dplyr::left_join(target, summary, by = tid)

  return(target)
}
```

### Load data.
* Buffalo zoning data.
* Census boundaries (2020) with population. 
 * Census block population_block
 * Census block group population_bg
* Microsoft building footprint (2018).
```{r}
landuse <- st_read("Data_GEO511_project/zoning.shp") 
source_geom <- st_read("Data_GEO511_project/census_bg.shp")
target_geom <- st_read("Data_GEO511_project/census_block.shp")
residential_bf <- st_read("Data_GEO511_project/residential_bf.shp")
#st_crs(residential_bf)
#st_crs(target_geom)
#st_crs(source_geom)
#st_crs(landuse)
```

### Clean required data

For building footprint data, we first filter the data using zoning data that has residential property. Then, make the source data, target data and ancillary data have the consistent crs.
Find [zoning codes](https://data.buffalony.gov/Economic-Neighborhood-Development/Zoning/5843-jknb) related to residential:
```{r}
### Residential zonings.The provided 'residential_bf.shp' already after filter using ArcGIS pro.
#residential_code = c('N-2R', 'N-3R', 'N-4-30', 'N-4-50', 'D-R')
#residential <- landuse %>% filter(gcode == residential_code) 
#residential_wgs84  <- residential %>%  st_transform(4326) 

# set projection for geometries.
target_geom_wgs84  <- target_geom %>%  st_transform(4326) 
source_geom_wgs84  <- source_geom %>%  st_transform(4326) 
```

### Disaggregate population 
The data was downscaling from source zone (census block group) to target zone (census block) using building footprint areas in the target zone as ancillary data. After downscaling, we would covert data as interger and` NA` as 0, due to population number can only be integer and larger than or equal to zero.
```{r dasymetric, warning=FALSE, message=FALSE}
# dasymetric map with building footprint information as ancillary data
sf_use_s2(FALSE)

dm_pop = dasymetric_map(target_geom_wgs84, source_geom_wgs84, residential_bf, extensive = "population")

# convert estimation result to integer, and replace NA as 0.
dm_pop[is.na(dm_pop)] <- 0 
dm_pop$population = as.integer(dm_pop$population)
```

# Results

Evaluating the result by plotting ground truth data and estimation result. Then, calculate R2 and coefficients.
[REFER TO](https://lukemiller.org/index.php/2012/10/adding-p-values-and-r-squared-values-to-a-plot-using-expression/)
The results shows R2 for this research is 0.62. We can see the potential by only use building footprint as ancillary data to downscaling population. It shows population distribution has high correlation with residential building distribution.
The plot shows the most block's population are less than 500. 
```{r}
#calculate r2 in dm_pop, 'population'(estimate) & 'Population'(ground truth)
mod1 = lm(Population~population, data = dm_pop)
modsum = summary(mod1)
plot(dm_pop$Population, dm_pop$population, type = 'p', las = 1,
		xlab = expression(paste('Census block Population')),
		ylab = 'Estimate population')

#adding the regression line from the linear model
abline(mod1)
```

```{r}
r2 = modsum$adj.r.squared
print(paste("R2 = ", r2))
```

```{r}
modsum$coefficients
```

Mapping. We are using `tmap` to show the ground truth and estimation result in a interactive map. By exploring the map, we can easily find the outliner location and discuss the reason.
```{r}
tm_shape(dm_pop) +
  tm_fill(col = c("population", "Population"), 
          style = "jenks", 
          title = c("Estimate_Population", "True_Population")) + 
  tm_facets(ncol = 2, sync = TRUE) +
  tmap_mode("view")
```


# Conclusions

Clear summary adequately describing the results and putting them in context. Discussion of further questions and ways to continue investigation.

# References

All sources are cited in a consistent manner

